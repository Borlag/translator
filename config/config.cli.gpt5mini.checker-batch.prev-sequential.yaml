llm:
  provider: openai
  model: gpt-5-mini
  system_prompt_path: ../general_prompt.md
  glossary_path: ../glossary.md
  temperature: 0.0
  max_output_tokens: 50000
  auto_model_sizing: false

checker:
  enabled: true
  provider: openai
  model: gpt-5-mini
  temperature: 0.0
  max_output_tokens: 20000
  fallback_segments_per_chunk: 120
  openai_batch_enabled: true
  auto_apply_safe: true
  auto_apply_min_confidence: 0.7

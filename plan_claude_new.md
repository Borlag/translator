Анализ завершён. Вот полный отчёт с рекомендациями.

---

# Аналитика и рекомендации по улучшению `docxru`

## Критические баги, которые прямо сейчас снижают качество

### 1. Checker использует НЕПРАВИЛЬНЫЙ system prompt
**`llm.py:972`** — при `task == "checker"` используется `self.translation_system_prompt` (промпт переводчика: "Ты профессиональный переводчик..."), а не специальный `CHECKER_SYSTEM_PROMPT` из `checker.py:22-25`. Модель получает противоречивые инструкции: "переводи" + "проверяй и возвращай JSON". Константа `CHECKER_SYSTEM_PROMPT` объявлена, но **никогда не используется**. Параметр `checker.system_prompt_path` из конфига тоже не подключён к LLM-клиенту.

### 2. Cleanup-правило ломает "Table of Contents"
**`pipeline.py:~127`** — правило `(re.compile(r"\bTable\b"), "Таблица")` заменяет ВСЕ вхождения "Table" на "Таблица", включая "Table of Contents" → "Таблица of Contents". Нужен guard: применять только когда за "Table" следует цифра.

### 3. Span-level fallback пропускает glossary shielding
**`pipeline.py:642-694`** — `_fallback_translate_by_spans` вызывает `_translate_shielded_fragment` напрямую, минуя `shield_terms()`. Термины, которые должны быть GLS-защищены, отправляются в LLM открытым текстом.

### 4. Ошибки в глоссарии
- **Deoxydine** = "Обезжиривающее средство" — это НЕВЕРНО. Deoxydine — кислотный дезоксидант, а не обезжириватель. Правильно: "Дезоксидирующее средство"
- **DPI/FPI** переводы перепутаны местами
- **Сплавы** (17-4PH, 15-5PH) перехватываются PN-паттерном до глоссария — русский перевод никогда не подставляется
- **Стандарты** (AMS-QQ-P-416) в soft-glossary заменят номер стандарта на описание

---

## Улучшения промптов (высокий импакт, без кода)

### 5. Разделить system prompt для checker-а
Текущий `CHECKER_SYSTEM_PROMPT` хорош, но не используется. Нужно:
- Подключить его как system prompt при `task == "checker"` вместо промпта переводчика
- Добавить калибровку severity:
  ```
  error = изменение смысла, пропуск safety-critical информации, неверный термин
  warn = стилистика, неоптимальный регистр, мелкие терминологические неточности  
  info = допустимые вариации, предпочтения стиля
  ```
- Добавить инструкцию по глоссарию: "Если термин есть в glossary_terms_used, suggested_target ОБЯЗАН использовать указанный перевод"
- Добавить: "Не флагируй проблемы, где текущий и предлагаемый варианты одинаково допустимы"

### 6. Расширить issue_type taxonomy checker-а
Текущий: `terminology|consistency|style|other`. Добавить: `meaning`, `omission`, `addition`, `number_error`, `register`, `untranslated`.

### 7. Оптимизировать `general_prompt.md`
- Убрать ~400 токенов мотивационного текста (описание PhD, стаж, etc.) — они не улучшают качество
- Удалить "Порядок работы" секцию — модель обрабатывает 1 сегмент, а не документ целиком
- Добавить negative examples: частые ошибки (калька герундия, пропуск прилагательных-квалификаторов, "torquing" вместо "затяжка")
- Устранить дублирование с `SYSTEM_PROMPT_TEMPLATE`

### 8. Различать контексты в user prompt
Сейчас `TM_REFERENCES` и `RECENT_TRANSLATIONS` выглядят одинаково (оба используют `=>`). Добавить инструкции:
- "TM_REFERENCES — переводы из базы данных (могут быть из других документов), используй как ориентир"
- "RECENT_TRANSLATIONS — только что выполненные переводы этого документа, поддерживай стилистическое единство"

---

## Улучшения кода (средний-высокий импакт)

### 9. Добавить недостающие валидаторы в `validator.py`

| Валидатор | Что ловит | Сложность |
|---|---|---|
| `validate_short_translation` | Подозрительно короткие переводы (ratio < 0.3) | Низкая |
| `validate_leaked_english` | Английские слова в русском выводе (кроме защищённых) | Средняя |
| `validate_duplicate_words` | "Штифт Штифт" — уже патчится в cleanup, но не отслеживается | Низкая |

### 10. Улучшить Token Shield
- Добавить паттерны для: ревизий (`Rev. A`, `Revision 2`), дат (ISO и текстовых), идентификаторов (`SB 1234-1`, `AD 2023-15-12`, `AMM 32-00-01`)
- Сделать PN паттерн case-insensitive (сейчас не ловит `mLG-12345`)
- Единица `m` (метр) слишком широкая: `\b5m\b` в подписи рисунка — это не размер. Нужен `\d+\s*mm?\b` с обязательным пробелом или двойной буквой
- Единица `A` (ампер): может ложно срабатывать на "Figure 5A". Нужен контекст или приоритет REF > DIM

### 11. Улучшить fuzzy TM matching
- `SequenceMatcher` — символьная метрика, не семантическая. Заменить или дополнить токен-уровневым Jaccard similarity
- FTS5 запрос использует `OR` — слишком шумный. Добавить BM25-ранжирование или использовать `AND` для хотя бы 50% токенов
- FTS токенизация `[A-Za-z0-9]{2,}` отбрасывает кириллицу — fuzzy disabled для смешанных текстов
- Добавить batch-write для TM вместо commit на каждый `put_exact`

### 12. Исправить batch retry logic
- Timeout retry отправляет тот же batch без уменьшения — гарантированный повторный timeout. Нужна бисекция (разбить batch пополам)
- Добавить `recent_translations` контекст в batch mode (хотя бы для первых N элементов группы)
- `_BATCH_PROVIDER_ALLOWLIST` расширить на другие провайдеры, поддерживающие JSON output

### 13. Consistency check — добавить frequency weighting
Если "скользящая трубка" встречается 47 раз, а "скользящая труба" — 1 раз, отмечать миноритарный вариант как отклонение, а не просто "есть два варианта".

---

## Локальная LLM — что развернуть и как

### Рекомендуемая 3-уровневая архитектура:

#### Уровень 1: COMETKiwi — автоматический QE scoring (CPU, бесплатно)
```bash
pip install unbabel-comet
```
Модель `wmt22-cometkiwi-da` (~300MB) принимает пары `(source, translation)` и возвращает score 0-1. Работает на CPU, 1-2 сек на сегмент. Интеграция:
- После перевода каждого сегмента — scoring
- Сегменты с score < 0.75 → автоматически отправляются в checker
- Сегменты с score > 0.85 → checker пропускает (экономия токенов)
- Score записывается в `qa.jsonl` как метрика качества

#### Уровень 2: TranslateGemma 12B или Qwen3 14B — локальный checker (GPU)
```bash
ollama pull translategemma:12b    # ~8 GB VRAM в Q4
# или
ollama pull qwen3:14b             # ~10 GB VRAM в Q4
```
Роль: второй checker pass после основного облачного checker-а. Локальная модель перепроверяет сегменты, где:
- COMETKiwi score < 0.75
- Облачный checker выдал предложения с confidence < 0.6
- Есть `numbers_mismatch` или `glossary_lemma_mismatch`

#### Уровень 3: Tower+ 9B — специализированный post-editor (опционально)
```bash
# Скачать GGUF с HuggingFace, загрузить через Ollama create
```
Tower+ специально обучен на post-editing и quality estimation, не только на перевод. Идеален как финальный "полировщик" для сегментов, прошедших через все предыдущие этапы и всё ещё имеющих issues.

### Интеграция в пайплайн:

```
[Перевод] → [Validator] → [COMETKiwi score] → [Cloud Checker] → [Local LLM recheck] → [Output]
                                   │                                        │
                              score > 0.85                            только если
                              → пропуск checker                    cloud checker не
                                                                   уверен (conf < 0.6)
```

Уже есть провайдер `ollama` в `llm.py` — нужно только:
1. Добавить новый pipeline stage `local_recheck` после checker pass
2. Создать отдельный `OllamaChatClient` для recheck-модели
3. Использовать `CHECKER_SYSTEM_PROMPT` (уже написан, просто не подключён)

---

## Дополнительные возможности для уникального качества

### 14. Back-translation verification
Переводим русский текст обратно на английский (дешёвой моделью или Google Free), сравниваем с оригиналом. Семантическое расхождение → автоматический флаг для перепроверки. Это мощный способ поймать meaning loss, который не ловится валидаторами.

### 15. Контекстное окно всего документа
Сейчас контекст — 3 предыдущих сегмента. Для consistency можно собирать "running glossary" из уже переведённых терминов документа и инжектить как `DOCUMENT_TERMS_SO_FAR`. Частично реализовано через `document_glossary`, но только для glossary-matched терминов.

### 16. A/B перевод
Для критических сегментов (заголовки, WARNING/CAUTION, процедурные шаги) — переводить двумя разными моделями (или двумя температурами), сравнивать COMETKiwi scores, брать лучший.

### 17. Ensemble post-processing
После перевода прогнать через лёгкую rule-based систему:
- Проверка Russian morphology (pymorphy3 уже подключен, но используется только для лемматизации)
- Согласование рода/числа/падежа в именных группах
- Стандартизация аббревиатур (ОШ, ПОШ, НДТ)

---

## Приоритетная дорожная карта

| # | Действие | Усилия | Импакт |
|---|---|---|---|
| 1 | Подключить `CHECKER_SYSTEM_PROMPT` | 30 мин | Критический |
| 2 | Исправить `\bTable\b` cleanup rule | 15 мин | Критический |
| 3 | Glossary fix: Deoxydine, DPI/FPI | 15 мин | Критический |
| 4 | Добавить glossary shielding в span fallback | 1 час | Высокий |
| 5 | Добавить validate_leaked_english | 2 часа | Высокий |
| 6 | Расширить token shield (Rev, даты, SB/AD) | 3 часа | Высокий |
| 7 | Интегрировать COMETKiwi scoring | 4 часа | Высокий |
| 8 | Severity calibration в checker prompt | 30 мин | Средний |
| 9 | Batch retry с бисекцией | 2 часа | Средний |
| 10 | Развернуть TranslateGemma 12B как local checker | 4 часа | Средний |
| 11 | Back-translation verification | 1 день | Средний |
| 12 | Улучшить fuzzy TM (Jaccard + Cyrillic FTS) | 1 день | Средний |

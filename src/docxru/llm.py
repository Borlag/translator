from __future__ import annotations

import json
import os
import re
import urllib.error
import urllib.parse
import urllib.request
from dataclasses import dataclass
from typing import Any, Protocol


class LLMClient(Protocol):
    supports_repair: bool

    def translate(self, text: str, context: dict[str, Any]) -> str: ...


SYSTEM_PROMPT_TEMPLATE = """–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –∞–≤–∏–∞—Ü–∏–æ–Ω–Ω–æ–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (CMM/AMM/IPC).

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
1) –°—Ç—Ä–æ–∫–∏/–º–∞—Ä–∫–µ—Ä—ã –≤–∏–¥–∞ ‚ü¶...‚üß –ù–ï–õ–¨–ó–Ø –º–µ–Ω—è—Ç—å, —É–¥–∞–ª—è—Ç—å, –ø–µ—Ä–µ—Å—Ç–∞–≤–ª—è—Ç—å, –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –∏–ª–∏ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ.
   –≠—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç:
   - –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã: ‚ü¶PN_1‚üß, ‚ü¶ATA_2‚üß, ‚ü¶DIM_3‚üß, ‚ü¶REF_4‚üß –∏ —Ç.–ø.
   - –º–∞—Ä–∫–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: ‚ü¶S_1|B|I‚üß ... ‚ü¶/S_1‚üß –∏ —Ç.–ø.
   –û—Å—Ç–∞–≤—å –∏—Ö –í –¢–û–ß–ù–û–°–¢–ò –∫–∞–∫ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ.

2) –ß–∏—Å–ª–∞, –∑–Ω–∞–∫–∏ ¬±, –¥–∏–∞–ø–∞–∑–æ–Ω—ã, –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è, —Å–∫–æ–±–∫–∏ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–π –∫–∞–∫ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º.

3) –ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ä—É—Å—Å–∫–∏–º:
   - –ø—Ä–æ—Ü–µ–¥—É—Ä—ã: –ø–æ–≤–µ–ª–∏—Ç–µ–ª—å–Ω–æ–µ –Ω–∞–∫–ª–æ–Ω–µ–Ω–∏–µ (‚Äú–°–Ω–∏–º–∏—Ç–µ‚Äù, ‚Äú–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ‚Äù, ‚Äú–ü—Ä–æ–≤–µ—Ä—å—Ç–µ‚Äù)
   - –±–µ–∑ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏, –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –æ—Ç —Å–µ–±—è
   - —Ç–µ—Ä–º–∏–Ω—ã –ø–æ –∞–≤–∏–∞—Ü–∏–æ–Ω–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (bolt = –±–æ–ª—Ç/–≤–∏–Ω—Ç –ø–æ —Å–º—ã—Å–ª—É, torque = –º–æ–º–µ–Ω—Ç –∑–∞—Ç—è–∂–∫–∏, washer = —à–∞–π–±–∞, etc.)
   - —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è –º–æ–∂–Ω–æ —Å–∫–ª–æ–Ω—è—Ç—å –∏ —Å–æ–≥–ª–∞—Å–æ–≤—ã–≤–∞—Ç—å –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
     (—Å–æ—Ö—Ä–∞–Ω—è–π –∑–Ω–∞—á–µ–Ω–∏–µ –∏ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –æ—Å–Ω–æ–≤—É, –Ω–µ ¬´–∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–π¬ª —Ñ–æ—Ä–º—É)

4) –ù–µ –¥–æ–±–∞–≤–ª—è–π –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π/–¥–æ–ø—É—â–µ–Ω–∏–π. –ü–µ—Ä–µ–≤–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±—É–∫–≤–∞–ª—å–Ω—ã–º –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º.

–ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –Ω–µ–ø–µ—Ä–µ–≤–æ–¥–∏–º—ã–π –∫–æ–¥/PN/–Ω–æ–º–µ—Ä/—Å—Å—ã–ª–∫–∞ ‚Äî –æ—Å—Ç–∞–≤—å –∫–∞–∫ –µ—Å—Ç—å (–æ–±—ã—á–Ω–æ —ç—Ç–æ —É–∂–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä).
"""


REPAIR_SYSTEM_PROMPT_TEMPLATE = """–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä/—Ä–µ–º–æ–Ω—Ç–Ω–∏–∫ –º–∞—Ä–∫–µ—Ä–æ–≤ –¥–ª—è DOCX –ø–µ—Ä–µ–≤–æ–¥–∞.

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
- –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–∞—Ä–∫–µ—Ä—ã –≤–∏–¥–∞ ‚ü¶...‚üß –≤ OUTPUT —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ —Å–æ–≤–ø–∞–ª–∏ —Å SOURCE.
- –ú–µ–Ω—è—Ç—å –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–Ω–µ –º–∞—Ä–∫–µ—Ä—ã) –ó–ê–ü–†–ï–©–ï–ù–û, –∫—Ä–æ–º–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–æ–∫ –ø—Ä–æ–±–µ–ª–æ–≤ –≤–æ–∫—Ä—É–≥ –º–∞—Ä–∫–µ—Ä–æ–≤,
  –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –≤—Å—Ç–∞–≤–∫–∏/–≤–ª–æ–∂–µ–Ω–∏—è –º–∞—Ä–∫–µ—Ä–æ–≤.

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:
- –ù–ï–õ–¨–ó–Ø –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å, –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å —Ç–µ–∫—Å—Ç.
- –ù–ï–õ–¨–ó–Ø –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –º–∞—Ä–∫–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ SOURCE.
- –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–õ–¨–ö–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π OUTPUT (–±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤).

–í—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç:
TASK: REPAIR_MARKERS

SOURCE:
...

OUTPUT:
...
"""

BATCH_SYSTEM_PROMPT_TEMPLATE = """You translate technical aviation text from English to Russian.
Return ONLY valid JSON in the requested schema.
Do not add commentary.
Preserve all marker tokens exactly (for example: ‚ü¶...‚üß / ü¶¶...üßß).
Preserve numbers, units, and punctuation.
"""

_JSON_FENCE_RE = re.compile(r"```(?:json)?\s*([\s\S]*?)\s*```", flags=re.IGNORECASE)

GlossaryReplacement = tuple[re.Pattern[str], str]
GlossaryMatcher = tuple[str, str, re.Pattern[str]]


def _compact_prompt_snippet(value: Any, *, max_chars: int = 180) -> str:
    text = re.sub(r"\s+", " ", str(value or "")).strip()
    if not text:
        return ""
    if len(text) <= max_chars:
        return text
    return text[: max_chars - 3].rstrip() + "..."


def _coerce_glossary_pairs(value: Any) -> list[tuple[str, str]]:
    if value is None:
        return []

    if isinstance(value, (list, tuple)):
        items = list(value)
    else:
        items = [value]

    pairs: list[tuple[str, str]] = []
    for item in items:
        source: Any = None
        target: Any = None
        if isinstance(item, dict):
            source = item.get("source")
            target = item.get("target")
        elif isinstance(item, (list, tuple)) and len(item) >= 2:
            source, target = item[0], item[1]

        if not isinstance(source, str) or not isinstance(target, str):
            continue
        source_text = source.strip()
        target_text = target.strip()
        if not source_text or not target_text:
            continue
        pairs.append((source_text, target_text))
    return pairs


def _format_matched_glossary_block(value: Any) -> str:
    pairs = _coerce_glossary_pairs(value)
    if not pairs:
        return ""
    lines = [f"- {source} -> {target}" for source, target in pairs]
    return "\n".join(lines)


def _format_recent_translations_block(value: Any, *, max_chars: int = 500) -> str:
    pairs = _coerce_glossary_pairs(value)
    if not pairs:
        return ""

    lines: list[str] = []
    consumed = 0
    budget = max(0, int(max_chars))
    for source, target in pairs:
        src = _compact_prompt_snippet(source, max_chars=120)
        tgt = _compact_prompt_snippet(target, max_chars=120)
        if not src or not tgt:
            continue
        line = f"- {src} => {tgt}"
        line_cost = len(line) + 1
        if budget > 0 and consumed + line_cost > budget:
            break
        lines.append(line)
        consumed += line_cost
    return "\n".join(lines)


def _format_tm_references_block(value: Any, *, max_chars: int = 500) -> str:
    if value is None:
        return ""

    if isinstance(value, (list, tuple)):
        items = list(value)
    else:
        items = [value]

    lines: list[str] = []
    consumed = 0
    budget = max(0, int(max_chars))
    for item in items:
        source: Any = None
        target: Any = None
        similarity: Any = None
        if isinstance(item, dict):
            source = item.get("source")
            target = item.get("target")
            similarity = item.get("similarity")
        elif isinstance(item, (list, tuple)) and len(item) >= 2:
            source, target = item[0], item[1]
            similarity = item[2] if len(item) > 2 else None
        if not isinstance(source, str) or not isinstance(target, str):
            continue
        src = _compact_prompt_snippet(source, max_chars=120)
        tgt = _compact_prompt_snippet(target, max_chars=120)
        if not src or not tgt:
            continue
        sim_txt = ""
        if isinstance(similarity, (int, float)):
            sim_txt = f" ({float(similarity):.2f})"
        line = f"-{sim_txt} {src} => {tgt}"
        line_cost = len(line) + 1
        if budget > 0 and consumed + line_cost > budget:
            break
        lines.append(line)
        consumed += line_cost
    return "\n".join(lines)


def build_user_prompt(text: str, context: dict[str, Any]) -> str:
    task = str(context.get("task", "translate")).lower()
    if task in {"repair", "batch_translate"}:
        return text

    # Context is kept short to reduce hallucination risk.
    ctx_parts: list[str] = []
    if context.get("section_header"):
        ctx_parts.append(f"SECTION: {context['section_header']}")
    if context.get("in_table"):
        ctx_parts.append("TABLE_CELL")
    if context.get("part"):
        ctx_parts.append(f"PART: {context.get('part')}")
    if not context.get("in_table"):
        prev_text = _compact_prompt_snippet(context.get("prev_text"))
        next_text = _compact_prompt_snippet(context.get("next_text"))
        if prev_text:
            ctx_parts.append(f"PREV: {prev_text}")
        if next_text:
            ctx_parts.append(f"NEXT: {next_text}")
    ctx = " | ".join(ctx_parts) if ctx_parts else "(no context)"

    extra_blocks: list[str] = []
    matched_glossary = _format_matched_glossary_block(context.get("matched_glossary_terms"))
    if matched_glossary:
        extra_blocks.append(f"MATCHED_GLOSSARY (EN -> RU):\n{matched_glossary}")

    document_glossary = _format_matched_glossary_block(context.get("document_glossary"))
    if document_glossary:
        extra_blocks.append(f"DOCUMENT_GLOSSARY (EN -> RU):\n{document_glossary}")

    raw_tm_max_chars = context.get("tm_references_max_chars", 500)
    try:
        tm_max_chars = int(raw_tm_max_chars)
    except (TypeError, ValueError):
        tm_max_chars = 500
    tm_references = _format_tm_references_block(context.get("tm_references"), max_chars=tm_max_chars)
    if tm_references:
        extra_blocks.append(f"TM_REFERENCES:\n{tm_references}")

    raw_recent_max_chars = context.get("recent_translations_max_chars", 500)
    try:
        recent_max_chars = int(raw_recent_max_chars)
    except (TypeError, ValueError):
        recent_max_chars = 500
    recent_translations = _format_recent_translations_block(
        context.get("recent_translations"),
        max_chars=recent_max_chars,
    )
    if recent_translations:
        extra_blocks.append(f"RECENT_TRANSLATIONS (EN => RU):\n{recent_translations}")

    extra_section = ""
    if extra_blocks:
        extra_section = "\n\n" + "\n\n".join(extra_blocks)
    return (
        "Use context only for disambiguation. Do not translate or repeat context in output.\n"
        f"Context: {ctx}{extra_section}\n\n"
        "Translate ONLY the text below:\n"
        f"{text}"
    )


def supports_repair(client: LLMClient) -> bool:
    return bool(getattr(client, "supports_repair", False))


def _extract_repair_output(text: str) -> str:
    raw = text or ""
    # Primary path: extract everything after the last OUTPUT: marker.
    marker = "OUTPUT:"
    idx = raw.upper().rfind(marker)
    if idx >= 0:
        return raw[idx + len(marker) :].lstrip("\r\n ").rstrip()

    # Fallback for markdown wrappers like ``` ... OUTPUT: ... ```
    m = re.search(r"```(?:text|md|markdown)?\s*([\s\S]*?)\s*```", raw, flags=re.IGNORECASE)
    if m:
        inner = m.group(1)
        idx2 = inner.upper().rfind(marker)
        if idx2 >= 0:
            return inner[idx2 + len(marker) :].lstrip("\r\n ").rstrip()
        return inner.strip()

    return raw


def _normalize_structured_output_mode(mode: str | None) -> str:
    value = (mode or "auto").strip().lower()
    if value not in {"off", "auto", "strict"}:
        raise ValueError(f"Unsupported structured_output_mode: {mode!r}")
    return value


def _extract_json_payload(raw: str) -> Any:
    text = (raw or "").strip()
    if not text:
        raise RuntimeError("Empty JSON response")

    candidates: list[str] = [text]
    for m in _JSON_FENCE_RE.finditer(text):
        fenced = (m.group(1) or "").strip()
        if fenced:
            candidates.append(fenced)

    obj_start = text.find("{")
    obj_end = text.rfind("}")
    if obj_start >= 0 and obj_end > obj_start:
        candidates.append(text[obj_start : obj_end + 1].strip())

    for candidate in candidates:
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            continue
    raise RuntimeError("Response is not valid JSON")


def _extract_structured_text(raw: str, *, field_name: str) -> str:
    payload = _extract_json_payload(raw)
    if not isinstance(payload, dict):
        raise RuntimeError("Structured response must be a JSON object")
    value = payload.get(field_name)
    if not isinstance(value, str):
        raise RuntimeError(f"Structured response missing string field: {field_name}")
    return value


def _is_gpt5_family(model: str) -> bool:
    return model.strip().lower().startswith("gpt-5")


def _supports_temperature(model: str, reasoning_effort: str | None) -> bool:
    m = model.strip().lower()
    if not _is_gpt5_family(m):
        return True
    if m.startswith("gpt-5.1") or m.startswith("gpt-5.2"):
        return (reasoning_effort or "").strip().lower() in {"", "none"}
    return False


def build_translation_system_prompt(
    base_system_prompt: str,
    *,
    custom_system_prompt: str | None = None,
    glossary_text: str | None = None,
) -> str:
    sections = [base_system_prompt.strip()]
    custom = (custom_system_prompt or "").strip()
    if custom:
        sections.append(f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:\n{custom}")
    glossary = (glossary_text or "").strip()
    if glossary:
        sections.append(f"–ì–ª–æ—Å—Å–∞—Ä–∏–π (EN -> RU, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ —Å–æ–±–ª—é–¥–∞—Ç—å):\n{glossary}")
    return "\n\n".join(sections)


def parse_glossary_pairs(glossary_text: str | None) -> list[tuple[str, str]]:
    if not glossary_text:
        return []

    def _strip_source_prefix(term: str) -> str:
        cleaned = term
        cleaned = re.sub(r"^\d+[.)]?\s*", "", cleaned)
        cleaned = cleaned.lstrip("‚Ä¢*- ").strip()
        return cleaned

    def _is_md_separator(cell: str) -> bool:
        return bool(re.fullmatch(r":?-{3,}:?", cell.strip()))

    pairs: list[tuple[str, str]] = []
    for raw_line in glossary_text.splitlines():
        line = raw_line.strip()
        if not line or line.startswith("#"):
            continue

        # Accept markdown table rows: | English | –†—É—Å—Å–∫–∏–π —Ç–µ—Ä–º–∏–Ω |
        if line.startswith("|") and line.endswith("|"):
            cols = [c.strip() for c in line.strip("|").split("|")]
            if len(cols) >= 2:
                source_term = cols[0]
                target_term = cols[1]
                if (
                    source_term
                    and target_term
                    and not (source_term.lower() == "english" and target_term.lower().startswith("—Ä—É—Å"))
                    and not (_is_md_separator(source_term) and _is_md_separator(target_term))
                ):
                    source_term = _strip_source_prefix(source_term)
                    if source_term and target_term:
                        pairs.append((source_term, target_term))
            continue

        # Accept lines like: "Downlocking Spring ‚Äî –ü—Ä—É–∂–∏–Ω–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏"
        m = re.match(r"^(.+?)\s+[‚Äî‚Äì-]\s+(.+)$", line)
        if not m:
            continue
        source_term = _strip_source_prefix(m.group(1).strip())
        target_term = m.group(2).strip()
        if not source_term or not target_term:
            continue
        pairs.append((source_term, target_term))

    pairs.sort(key=lambda item: len(item[0]), reverse=True)
    return pairs


def _compile_term_pattern(source_term: str) -> re.Pattern[str]:
    escaped = re.escape(source_term.strip())
    gap = r"(?:\s+|‚ü¶BR(?:LINE|COL|PAGE)_\d+‚üß)+"
    optional_gap = r"(?:\s+|‚ü¶BR(?:LINE|COL|PAGE)_\d+‚üß)*"
    # OCR/Word converted manuals often insert hard line-wraps and variable spaces around hyphens.
    # Make term matching tolerant to those artifacts so phrase-level glossary enforcement still works.
    escaped = escaped.replace(r"\ ", gap)
    escaped = escaped.replace(r"\-", rf"{optional_gap}-{optional_gap}")
    if re.search(r"[A-Za-z0-9]", source_term):
        # Restrict replacements to standalone ASCII terms to avoid accidental partial matches.
        return re.compile(rf"(?<![A-Za-z0-9]){escaped}(?![A-Za-z0-9])", flags=re.IGNORECASE)
    return re.compile(escaped, flags=re.IGNORECASE)


def build_glossary_matchers(glossary_text: str | None) -> tuple[GlossaryMatcher, ...]:
    matchers: list[GlossaryMatcher] = []
    for source_term, target_term in parse_glossary_pairs(glossary_text):
        matchers.append((source_term, target_term, _compile_term_pattern(source_term)))
    return tuple(matchers)


def select_matched_glossary_terms(
    text: str,
    matchers: tuple[GlossaryMatcher, ...],
    *,
    limit: int = 24,
) -> list[tuple[str, str]]:
    if not text or not matchers:
        return []

    max_terms = max(0, int(limit))
    if max_terms == 0:
        return []

    seen_sources: set[str] = set()
    matched: list[tuple[str, str]] = []
    for source_term, target_term, pattern in matchers:
        source_key = source_term.strip().lower()
        if not source_key or source_key in seen_sources:
            continue
        if not pattern.search(text):
            continue
        seen_sources.add(source_key)
        matched.append((source_term, target_term))
        if len(matched) >= max_terms:
            break
    return matched


DOMAIN_TERM_PAIRS: tuple[tuple[str, str], ...] = (
    # Cover-page legal small print: keep these translations concise to avoid layout overflow.
    (
        "This document and all information contained herein is the sole property of Safran Landing Systems (and/or its affiliated companies).",
        "–î–æ–∫—É–º–µ–Ω—Ç –∏ –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å Safran Landing Systems (–∏/–∏–ª–∏ –∞—Ñ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π).",
    ),
    (
        "No intellectual property rights are granted by the delivery of this document or the disclosure of its content.",
        "–ü—Ä–∞–≤–∞ –ò–° –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è.",
    ),
    (
        "This document shall not be reproduced to a third party without the express written consent of Safran Landing Systems (and/or the appropriate affiliated company).",
        "–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —Ç—Ä–µ—Ç—å–∏–º –ª–∏—Ü–∞–º - —Ç–æ–ª—å–∫–æ —Å –ø–∏—Å—å–º–µ–Ω–Ω–æ–≥–æ —Å–æ–≥–ª–∞—Å–∏—è Safran Landing Systems.",
    ),
    # Frequent SB-description lines in ABBYY-converted manuals.
    (
        "MLG - Installation of stub bolt subassembly for the forward pintle pin in place of the cross bolt.",
        "MLG - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ–¥—Å–±–æ—Ä–∫–∏ –±–æ–ª—Ç–∞-–∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è –ø–µ—Ä–µ–¥–Ω–µ–≥–æ —à–∫–≤–æ—Ä–Ω–µ–≤–æ–≥–æ —à—Ç–∏—Ñ—Ç–∞ –≤–º–µ—Å—Ç–æ –ø–æ–ø–µ—Ä–µ—á–Ω–æ–≥–æ –±–æ–ª—Ç–∞.",
    ),
    (
        "MLG - To allow an increase in aircraft maximum take-off weight to 93 tonne.",
        "MLG - –î–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–∑–ª–µ—Ç–Ω–æ–π –º–∞—Å—Å—ã —Å–∞–º–æ–ª–µ—Ç–∞ –¥–æ 93 —Ç.",
    ),
    (
        "MLG -To add tracking numbers to parts listed in Airbus Airworthiness Limitations Section (ALS).",
        "MLG - –î–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–º–µ—Ä–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫ –¥–µ—Ç–∞–ª—è–º, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–º –≤ —Ä–∞–∑–¥–µ–ª–µ Airbus Airworthiness Limitations Section (ALS).",
    ),
    (
        "MLG - Installation of a 201585 series MLG Leg and Dressings where a 201387 MLG Leg and Dressings has been installed.",
        "MLG - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–π–∫–∏ MLG —Å–µ—Ä–∏–∏ 201585 –∏ –∫–æ–º–ø–ª–µ–∫—Ç–æ–≤ dressings –≤–º–µ—Å—Ç–æ —Ä–∞–Ω–µ–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π —Å—Ç–æ–π–∫–∏ MLG —Å–µ—Ä–∏–∏ 201387 –∏ –∫–æ–º–ø–ª–µ–∫—Ç–æ–≤ dressings.",
    ),
    (
        "MLG -To add tracking numbers to parts listed in Airbus Maintenance Planning Document, Section 9-1. (Torque link apex pin nut)",
        "MLG - –î–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–º–µ—Ä–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫ –¥–µ—Ç–∞–ª—è–º, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–º –≤ Airbus Maintenance Planning Document, —Ä–∞–∑–¥–µ–ª 9-1. (–ì–∞–π–∫–∞ —à–∫–≤–æ—Ä–Ω–µ–≤–æ–≥–æ —à—Ç–∏—Ñ—Ç–∞ –≤–µ—Ä—à–∏–Ω—ã —Ä—ã—á–∞–≥–∞ –∫—Ä—É—Ç—è—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞)",
    ),
    ("MLG - Introduction of a new lower bearing subassembly.", "MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –Ω–∏–∂–Ω–µ–≥–æ —É–∑–ª–∞ –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞."),
    ("MLG - Introduction of new charging labels", "MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–∞—Ä–∫–∏—Ä–æ–≤–æ—á–Ω—ã—Ö —Ç–∞–±–ª–∏—á–µ–∫."),
    ("MLG - Introduction of new 1M and 2M Axle harnesses", "MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∂–≥—É—Ç–æ–≤ –æ—Å–∏ 1M –∏ 2M."),
    (
        "MLG - Introduction of new 1M and 2M Leg Harness and of new 1M and 2M Axle Harnesses",
        "MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∂–≥—É—Ç–æ–≤ —Å—Ç–æ–π–∫–∏ 1M –∏ 2M, –∞ —Ç–∞–∫–∂–µ –Ω–æ–≤—ã—Ö –∂–≥—É—Ç–æ–≤ –æ—Å–∏ 1M –∏ 2M.",
    ),
    (
        "MLG Leg-Introduction of new retaining pins and a new lower bearing subassembly with a new self lubricating liner",
        "–°—Ç–æ–π–∫–∞ MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å—Ç–æ–ø–æ—Ä–Ω—ã—Ö —à—Ç–∏—Ñ—Ç–æ–≤ –∏ –Ω–æ–≤–æ–≥–æ –Ω–∏–∂–Ω–µ–≥–æ —É–∑–ª–∞ –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞ —Å –Ω–æ–≤—ã–º —Å–∞–º–æ—Å–º–∞–∑—ã–≤–∞—é—â–∏–º—Å—è –≤–∫–ª–∞–¥—ã—à–µ–º.",
    ),
    (
        "MLG Leg - Introduction of new retaining pins for the lower bearing subassembly",
        "–°—Ç–æ–π–∫–∞ MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å—Ç–æ–ø–æ—Ä–Ω—ã—Ö —à—Ç–∏—Ñ—Ç–æ–≤ –¥–ª—è –Ω–∏–∂–Ω–µ–≥–æ —É–∑–ª–∞ –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞.",
    ),
    (
        "MLG Leg - Introduction of a new lower bearing subassembly with a new low friction inner liner",
        "–°—Ç–æ–π–∫–∞ MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –Ω–∏–∂–Ω–µ–≥–æ —É–∑–ª–∞ –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞ —Å –Ω–æ–≤—ã–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –≤–∫–ª–∞–¥—ã—à–µ–º —Å –Ω–∏–∑–∫–∏–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º —Ç—Ä–µ–Ω–∏—è.",
    ),
    (
        "MLG Leg - Barkhausen Noise Inspection of Main Landing Gear Sliding Tube Axles.",
        "–°—Ç–æ–π–∫–∞ MLG - –ö–æ–Ω—Ç—Ä–æ–ª—å —à—É–º–∞ –ë–∞—Ä–∫—Ö–∞—É–∑–µ–Ω–∞ –æ—Å–µ–π —Å–∫–æ–ª—å–∑—è—â–µ–π —Ç—Ä—É–±—ã –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–æ–π–∫–∏ —à–∞—Å—Å–∏.",
    ),
    ("MLG Leg - Introduction of a new Main Fitting", "–°—Ç–æ–π–∫–∞ MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞ —Å—Ç–æ–π–∫–∏."),
    ("MLG Leg - Introduction of a new torque link damper unit", "–°—Ç–æ–π–∫–∞ MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –¥–µ–º–ø—Ñ–µ—Ä–Ω–æ–≥–æ —É–∑–ª–∞ —Ä—ã—á–∞–≥–∞ –∫—Ä—É—Ç—è—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞."),
    (
        "MLG Leg - Introduction of a new main fitting subassembly and related parts",
        "–°—Ç–æ–π–∫–∞ MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–π –ø–æ–¥—Å–±–æ—Ä–∫–∏ –∫–æ—Ä–ø—É—Å–∞ —Å—Ç–æ–π–∫–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π.",
    ),
    ("MLG - Introduction of a new upper pivot bracket", "MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –≤–µ—Ä—Ö–Ω–µ–≥–æ –∫—Ä–æ–Ω—à—Ç–µ–π–Ω–∞ —à–∞—Ä–Ω–∏—Ä–∞."),
    ("MLG - Introduction of a new changeover valve stem and housing", "MLG - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —à—Ç–æ–∫–∞ –∏ –∫–æ—Ä–ø—É—Å–∞ –ø–µ—Ä–µ–∫–ª—é—á–∞—é—â–µ–≥–æ –∫–ª–∞–ø–∞–Ω–∞."),
    ("MLG complete - Introduction of a new transfer block subassembly", "–°—Ç–æ–π–∫–∞ MLG –≤ —Å–±–æ—Ä–µ - –í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–π –ø–æ–¥—Å–±–æ—Ä–∫–∏ –ø–µ—Ä–µ—Ö–æ–¥–Ω–æ–≥–æ –±–ª–æ–∫–∞."),
    ("MLG Complete - Modification of the transfer block subassembly", "–°—Ç–æ–π–∫–∞ MLG –≤ —Å–±–æ—Ä–µ - –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–¥—Å–±–æ—Ä–∫–∏ –ø–µ—Ä–µ—Ö–æ–¥–Ω–æ–≥–æ –±–ª–æ–∫–∞."),
    (
        "MLG - Conversion of low - friction lower - bearing MLG to standard lower - bearing MLG",
        "MLG - –ü–µ—Ä–µ—Ö–æ–¥ –æ—Ç –Ω–∏–∂–Ω–µ–≥–æ –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞ MLG —Å –Ω–∏–∑–∫–∏–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º —Ç—Ä–µ–Ω–∏—è –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –Ω–∏–∂–Ω–µ–º—É –ø–æ–¥—à–∏–ø–Ω–∏–∫—É MLG.",
    ),
    ("Record of Temporary Revisions", "–ó–∞–ø–∏—Å—å –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π"),
    ("Record of Revisions", "–ó–∞–ø–∏—Å—å –∏–∑–º–µ–Ω–µ–Ω–∏–π"),
    ("Revision Record", "–ó–∞–ø–∏—Å—å –∏–∑–º–µ–Ω–µ–Ω–∏–π"),
    ("List of Effective Pages", "–°–ø–∏—Å–æ–∫ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"),
    ("List of Effective Pages (Continued)", "–°–ø–∏—Å–æ–∫ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ)"),
    ("List of Service Bulletins", "–°–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–∏—Å–Ω—ã—Ö –±—é–ª–ª–µ—Ç–µ–Ω–µ–π"),
    ("New/Revised Pages", "–ù–æ–≤—ã–µ/–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"),
    ("Table of Contents", "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"),
    ("Table of Contents (Continued)", "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ)"),
    ("Fig. Page", "–†–∏—Å. –°—Ç—Ä–∞–Ω–∏—Ü–∞"),
    ("Fig Page", "–†–∏—Å. –°—Ç—Ä–∞–Ω–∏—Ü–∞"),
    ("Subject Reference", "–¢–µ–º–∞/—Å—Å—ã–ª–∫–∞"),
    ("Remove and Destroy Pages", "–£–¥–∞–ª–∏—Ç—å –∑–∞–º–µ–Ω—è–µ–º—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"),
    ("Insert New/Revised", "–í—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ/–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ"),
    ("Reason for Change", "–ü—Ä–∏—á–∏–Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è"),
    ("Added fig-item", "–î–æ–±–∞–≤–ª–µ–Ω —ç–ª–µ–º–µ–Ω—Ç —Ä–∏—Å—É–Ω–∫–∞"),
    ("Updated fig-items", "–û–±–Ω–æ–≤–ª–µ–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã —Ä–∏—Å—É–Ω–∫–∞"),
    ("fig-item", "—ç–ª–µ–º–µ–Ω—Ç —Ä–∏—Å—É–Ω–∫–∞"),
    ("fig-items", "—ç–ª–µ–º–µ–Ω—Ç—ã —Ä–∏—Å—É–Ω–∫–∞"),
    ("Updated Messier-Dowty Limited to Safran Landing Systems", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ Messier-Dowty Limited –∏–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ Safran Landing Systems"),
    ("Updated conversion value in figure", "–û–±–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ"),
    ("MLG Leg", "–°—Ç–æ–π–∫–∞ MLG"),
    ("MLG Complete", "–°—Ç–æ–π–∫–∞ MLG –≤ —Å–±–æ—Ä–µ"),
    ("MLG complete", "–°—Ç–æ–π–∫–∞ MLG –≤ —Å–±–æ—Ä–µ"),
    ("Introduction of new", "–í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö"),
    ("Introduction of a new", "–í–≤–µ–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ"),
    ("transfer block subassembly", "–ø–æ–¥—Å–±–æ—Ä–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–Ω–æ–≥–æ –±–ª–æ–∫–∞"),
    ("lower bearing subassembly", "–Ω–∏–∂–Ω–∏–π —É–∑–µ–ª –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞"),
    ("Barkhausen Noise Inspection", "–∫–æ–Ω—Ç—Ä–æ–ª—å —à—É–º–∞ –ë–∞—Ä–∫—Ö–∞—É–∑–µ–Ω–∞"),
    ("Main Landing Gear Sliding Tube Axles", "–æ—Å–∏ —Å–∫–æ–ª—å–∑—è—â–µ–π —Ç—Ä—É–±—ã –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–æ–π–∫–∏ —à–∞—Å—Å–∏"),
    ("torque link damper unit", "–¥–µ–º–ø—Ñ–µ—Ä–Ω—ã–π —É–∑–µ–ª —Ä—ã—á–∞–≥–∞ –∫—Ä—É—Ç—è—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞"),
    ("changeover valve stem and housing", "—à—Ç–æ–∫ –∏ –∫–æ—Ä–ø—É—Å –ø–µ—Ä–µ–∫–ª—é—á–∞—é—â–µ–≥–æ –∫–ª–∞–ø–∞–Ω–∞"),
    ("Airworthiness Limitations Section", "—Ä–∞–∑–¥–µ–ª –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ª–µ—Ç–Ω–æ–π –≥–æ–¥–Ω–æ—Å—Ç–∏"),
    ("Maintenance Planning Document", "–¥–æ–∫—É–º–µ–Ω—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è"),
    ("tracking numbers", "–Ω–æ–º–µ—Ä–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è"),
    ("stub bolt subassembly", "–ø–æ–¥—Å–±–æ—Ä–∫–∞ –±–æ–ª—Ç–∞-–∑–∞–≥–ª—É—à–∫–∏"),
    ("self lubricating liner", "—Å–∞–º–æ—Å–º–∞–∑—ã–≤–∞—é—â–∏–π—Å—è –≤–∫–ª–∞–¥—ã—à"),
    ("low friction inner liner", "–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –≤–∫–ª–∞–¥—ã—à —Å –Ω–∏–∑–∫–∏–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º —Ç—Ä–µ–Ω–∏—è"),
    ("Axle Harnesses", "–∂–≥—É—Ç—ã –æ—Å–∏"),
    ("Axle harnesses", "–∂–≥—É—Ç—ã –æ—Å–∏"),
    ("Leg Harness", "–∂–≥—É—Ç —Å—Ç–æ–π–∫–∏"),
    ("Main Landing Gear Leg", "–û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–æ–π–∫–∞ —à–∞—Å—Å–∏"),
    ("Lower Torque Link", "–ù–∏–∂–Ω–∏–π —Ä—ã—á–∞–≥ –∫—Ä—É—Ç—è—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞"),
    ("Upper Torque Link", "–í–µ—Ä—Ö–Ω–∏–π —Ä—ã—á–∞–≥ –∫—Ä—É—Ç—è—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞"),
    ("Sliding Tube", "–°–∫–æ–ª—å–∑—è—â–∞—è —Ç—Ä—É–±–∫–∞"),
    ("Transfer Block", "–ü–µ—Ä–µ—Ö–æ–¥–Ω–æ–π –±–ª–æ–∫"),
    ("Spherical Bearing", "–°—Ñ–µ—Ä–∏—á–µ—Å–∫–∏–π –ø–æ–¥—à–∏–ø–Ω–∏–∫"),
    ("Pivot Bracket", "–ö—Ä–æ–Ω—à—Ç–µ–π–Ω —à–∞—Ä–Ω–∏—Ä–∞"),
    ("Harness Support Bracket", "–ö—Ä–æ–Ω—à—Ç–µ–π–Ω –∫—Ä–µ–ø–ª–µ–Ω–∏—è –∂–≥—É—Ç–∞"),
    ("Retaining Pin", "–§–∏–∫—Å–∏—Ä—É—é—â–∏–π —à—Ç–∏—Ñ—Ç"),
    ("Pintle Pin", "–®–∫–≤–æ—Ä–Ω–µ–≤–æ–π —à—Ç–∏—Ñ—Ç"),
    ("Forward Pintle Pin", "–ü–µ—Ä–µ–¥–Ω–∏–π —à–∫–≤–æ—Ä–Ω–µ–≤–æ–π —à—Ç–∏—Ñ—Ç"),
    ("Uplock Pin", "–®—Ç–∏—Ñ—Ç –∞–ø–ª–æ–∫–∞"),
    ("Main Fitting", "–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∏—Ç–∏–Ω–≥"),
    ("Protective Treatment", "–ó–∞—â–∏—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"),
    ("Repair No.", "–†–µ–º–æ–Ω—Ç ‚Ññ"),
    ("Lower", "–ù–∏–∂–Ω–∏–π"),
    ("Upper", "–í–µ—Ä—Ö–Ω–∏–π"),
    ("Torque", "–ö—Ä—É—Ç—è—â–∏–π –º–æ–º–µ–Ω—Ç"),
    ("Link", "–†—ã—á–∞–≥"),
    ("Repair", "–†–µ–º–æ–Ω—Ç"),
    ("Sheet", "–õ–∏—Å—Ç"),
    ("Withdrawn", "–ê–Ω–Ω—É–ª–∏—Ä–æ–≤–∞–Ω–æ"),
    ("Illustrations", "–ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏"),
    ("Blank", "–ü—É—Å—Ç–æ"),
    ("Fig.", "–†–∏—Å."),
    ("Fig", "–†–∏—Å"),
    ("Subject", "–¢–µ–º–∞"),
    ("Table", "–¢–∞–±–ª–∏—Ü–∞"),
    ("List", "–°–ø–∏—Å–æ–∫"),
    ("Part No.", "–ù–æ–º–µ—Ä –¥–µ—Ç–∞–ª–∏"),
    ("Part", "–î–µ—Ç–∞–ª—å"),
    ("Revision", "–†–µ–≤–∏–∑–∏—è"),
    ("New/Revised", "–ù–æ–≤—ã–µ/–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ"),
    ("Uplock", "–ê–ø–ª–æ–∫"),
    ("No.", "‚Ññ"),
)


def build_domain_replacements(*, include_single_words: bool = False) -> tuple[GlossaryReplacement, ...]:
    """Static aviation-doc replacements to reduce EN leftovers in translated output."""
    term_pairs = list(DOMAIN_TERM_PAIRS)
    if not include_single_words:
        term_pairs = [item for item in term_pairs if re.search(r"\s", item[0])]
    term_pairs.sort(key=lambda item: len(item[0]), reverse=True)
    return tuple((_compile_term_pattern(source), target) for source, target in term_pairs)


def build_hard_glossary_replacements(glossary_text: str | None) -> tuple[GlossaryReplacement, ...]:
    """Build replacements intended for pre-translation shielding (hard glossary).

    For quality/safety, this includes:
    - user glossary pairs (exact EN -> RU)
    - selected domain phrases (multi-word only), to fix common headings in free providers

    User glossary entries override domain defaults for the same source term.
    """
    domain_pairs = [item for item in DOMAIN_TERM_PAIRS if re.search(r"\s", item[0])]
    glossary_pairs = [item for item in parse_glossary_pairs(glossary_text) if re.search(r"\s", item[0])]

    # Deduplicate source terms case-insensitively; user glossary overrides domain defaults.
    merged: dict[str, tuple[str, str]] = {}
    for src, tgt in domain_pairs:
        key = src.strip().lower()
        if key:
            merged.setdefault(key, (src, tgt))
    for src, tgt in glossary_pairs:
        key = src.strip().lower()
        if key:
            merged[key] = (src, tgt)

    pairs = list(merged.values())
    pairs.sort(key=lambda item: len(item[0]), reverse=True)
    return tuple((_compile_term_pattern(source), target) for source, target in pairs)


def build_glossary_replacements(glossary_text: str | None) -> tuple[GlossaryReplacement, ...]:
    replacements: list[GlossaryReplacement] = []
    for source_term, target_term, pattern in build_glossary_matchers(glossary_text):
        replacements.append((pattern, target_term))
    return tuple(replacements)


def apply_glossary_replacements(text: str, replacements: tuple[GlossaryReplacement, ...]) -> str:
    out = text
    for pattern, replacement in replacements:
        out = pattern.sub(replacement, out)

    # Canonical EN heading fallback (for partially untranslated outputs).
    out = re.sub(r"\bMain Landing Gear Leg\b", "–°—Ç–æ–π–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —à–∞—Å—Å–∏", out, flags=re.IGNORECASE)
    out = re.sub(r"\bRepair Procedure Conditions\b", "–£—Å–ª–æ–≤–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ—Ü–µ–¥—É—Ä—ã —Ä–µ–º–æ–Ω—Ç–∞", out, flags=re.IGNORECASE)
    out = re.sub(r"\bMLG\s+Leg\b", "–°—Ç–æ–π–∫–∞ MLG", out, flags=re.IGNORECASE)
    out = re.sub(r"\bList of Effective Pages\b", "–ü–µ—Ä–µ—á–µ–Ω—å –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü", out, flags=re.IGNORECASE)
    out = re.sub(r"\bRevision Record\b", "–ó–∞–ø–∏—Å—å –∏–∑–º–µ–Ω–µ–Ω–∏–π", out, flags=re.IGNORECASE)
    out = re.sub(r"\bDate Incorporated Into Manual\b", "–î–∞—Ç–∞ –≤–∫–ª—é—á–µ–Ω–∏—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ", out, flags=re.IGNORECASE)
    out = re.sub(r"\bInsert New/Revised Pages\b", "–í—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ/–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã", out, flags=re.IGNORECASE)
    out = re.sub(r"\bRemove and Destroy Pages\b", "–£–¥–∞–ª–∏—Ç—å –∏ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã", out, flags=re.IGNORECASE)
    out = re.sub(r"\bReason for Change\b", "–ü—Ä–∏—á–∏–Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è", out, flags=re.IGNORECASE)
    out = re.sub(r"\bSubject/?Reference\b", "–¢–µ–º–∞/—Å—Å—ã–ª–∫–∞", out, flags=re.IGNORECASE)
    out = re.sub(r"\bService Bulletin List\b", "–°–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–∏—Å–Ω—ã—Ö –±—é–ª–ª–µ—Ç–µ–Ω–µ–π", out, flags=re.IGNORECASE)
    out = re.sub(r"\bMain Fitting Subassembly\b", "–ü–æ–¥—Å–±–æ—Ä–∫–∞ –∫–æ—Ä–ø—É—Å–∞ —Å—Ç–æ–π–∫–∏", out, flags=re.IGNORECASE)
    out = re.sub(r"\bSubassembly\b", "–ø–æ–¥—Å–±–æ—Ä–∫–∞", out, flags=re.IGNORECASE)
    out = re.sub(r"\bIPL\s+FIGURE\b", "IPL –†–ò–°–£–ù–û–ö", out, flags=re.IGNORECASE)
    out = re.sub(r"\bIPL\s+fig\b", "IPL —Ä–∏—Å.", out, flags=re.IGNORECASE)
    out = re.sub(r"\b(?:fig\.?|figure)\b", "—Ä–∏—Å.", out, flags=re.IGNORECASE)
    out = re.sub(r"\bfig\s*\(", "—Ä–∏—Å. (", out, flags=re.IGNORECASE)

    # Mixed heading cleanup for partial machine translations.
    out = re.sub(r"\bSubject\s+–°—Å—ã–ª–∫–∞\b", "–¢–µ–º–∞/—Å—Å—ã–ª–∫–∞", out, flags=re.IGNORECASE)
    out = re.sub(r"\b–¢–µ–º–∞\s+–°—Å—ã–ª–∫–∞\b", "–¢–µ–º–∞/—Å—Å—ã–ª–∫–∞", out, flags=re.IGNORECASE)
    out = re.sub(r"\b–í—Å—Ç–∞–≤–∏—Ç—å\s+–Ω–æ–≤—ã–π/–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π\b", "–í—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ/–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ", out, flags=re.IGNORECASE)
    out = re.sub(r"\b–í—Å—Ç–∞–≤–∏—Ç—å\s+–Ω–æ–≤—ã–π/–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–π\b", "–í—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ/–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ", out, flags=re.IGNORECASE)
    out = re.sub(r"\bNEW/REVISED\s+–°–¢–†–ê–ù–ò–¶–´\b", "–ù–û–í–´–ï/–ü–ï–†–ï–°–ú–û–¢–†–ï–ù–ù–´–ï –°–¢–†–ê–ù–ò–¶–´", out, flags=re.IGNORECASE)
    out = re.sub(r"\bREVISION\s+–ó–ê–ü–ò–°–¨\b", "–ó–ê–ü–ò–°–¨ –ò–ó–ú–ï–ù–ï–ù–ò–ô", out, flags=re.IGNORECASE)
    out = re.sub(r"\bLIST\s+–°–ï–†–í–ò–°–ù–´–•\s+–ë–Æ–õ–õ–ï–¢–ï–ù–ï–ô\b", "–°–ü–ò–°–û–ö –°–ï–†–í–ò–°–ù–´–• –ë–Æ–õ–õ–ï–¢–ï–ù–ï–ô", out, flags=re.IGNORECASE)
    out = re.sub(r"\bPART\s+‚Ññ\b", "‚Ññ –î–ï–¢–ê–õ–ò", out, flags=re.IGNORECASE)
    out = re.sub(r"\btable\s+(\d+)\b", r"—Ç–∞–±–ª–∏—Ü–∞ \1", out, flags=re.IGNORECASE)
    out = re.sub(r"\(Table\s+(\d+)\)", r"(—Ç–∞–±–ª–∏—Ü–∞ \1)", out, flags=re.IGNORECASE)
    out = re.sub(r"\bFig\.\s+–°—Ç—Ä–∞–Ω–∏—Ü–∞\b", "–†–∏—Å. –°—Ç—Ä–∞–Ω–∏—Ü–∞", out, flags=re.IGNORECASE)
    out = re.sub(r"\b—ç–ª–µ–º–µ–Ω—Ç\s+—Ä–∏—Å–∞\b", "—ç–ª–µ–º–µ–Ω—Ç —Ä–∏—Å—É–Ω–∫–∞", out, flags=re.IGNORECASE)
    out = re.sub(r"\bMLG\s+–ù–æ–≥–∞\b", "–°—Ç–æ–π–∫–∞ MLG", out, flags=re.IGNORECASE)
    out = re.sub(r"\b–ù–æ–≥–∞\s+MLG\b", "–°—Ç–æ–π–∫–∞ MLG", out, flags=re.IGNORECASE)
    out = re.sub(r"\b–û–ø–æ—Ä–∞\s+MLG\b", "–°—Ç–æ–π–∫–∞ MLG", out, flags=re.IGNORECASE)
    out = re.sub(r"\b–í–µ—Ç–∫–∞\s+MLG\b", "–°—Ç–æ–π–∫–∞ MLG", out, flags=re.IGNORECASE)
    out = re.sub(r"\bMLG\s+–∑–∞–≤–µ—Ä—à–µ–Ω–æ\b", "–°—Ç–æ–π–∫–∞ MLG –≤ —Å–±–æ—Ä–µ", out, flags=re.IGNORECASE)
    out = re.sub(
        r"\b–û–±–Ω–æ–≤–ª–µ–Ω–∞\s+–∫–æ–º–ø–∞–Ω–∏—è\s+Messier-Dowty\s+Limited\s+–¥–ª—è\s+Safran\s+Landing\s+Systems\b",
        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ Messier-Dowty Limited –∏–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ Safran Landing Systems",
        out,
        flags=re.IGNORECASE,
    )
    out = re.sub(
        r"\b–ö–æ–º–ø–∞–Ω–∏—è\s+Messier-Dowty\s+Limited\s+–æ–±–Ω–æ–≤–ª–µ–Ω–∞\s+–¥–æ\s+Safran\s+Landing\s+System[s]?\b",
        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ Messier-Dowty Limited –∏–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ Safran Landing Systems",
        out,
        flags=re.IGNORECASE,
    )
    out = re.sub(
        r"\b–û–±–Ω–æ–≤–ª–µ–Ω–Ω[–∞-—è]+\s+—Ü–µ–Ω–Ω–æ—Å—Ç[–∞-—è]+\s+–∫–æ–Ω–≤–µ—Ä—Å–∏–∏\b",
        "–û–±–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ—Å—á–µ—Ç–∞",
        out,
        flags=re.IGNORECASE,
    )
    # Keep heading joiners consistent in OCR/PDF-converted manuals.
    out = re.sub(r"(?m)^\s*WITH\s*$", "–°", out, flags=re.IGNORECASE)
    out = re.sub(r"(‚ü¶PN_\d+‚üß)\s+AND\s+(‚ü¶PN_\d+‚üß)", r"\1 –ò \2", out, flags=re.IGNORECASE)

    # TOC artifact cleanup: merged "Repair No. X-Y601" -> "–†–µ–º–æ–Ω—Ç ‚Ññ X-Y 601"
    out = re.sub(r"–†–µ–º–æ–Ω—Ç\s*‚Ññ\s*(\d+-\d+)(\d{3,4})\b", r"–†–µ–º–æ–Ω—Ç ‚Ññ \1 \2", out)
    out = re.sub(r"(–†–µ–º–æ–Ω—Ç\s*‚Ññ\s*\d+-\d+)\s+–†–µ–º–æ–Ω—Ç\s+", r"\1 ", out, flags=re.IGNORECASE)
    out = re.sub(r"‚Ññ\s*(\d+-\d+)(\d{3,4})\b", r"‚Ññ \1 \2", out)
    # Normalize occasional machine-translated abbreviation variants.
    out = out.replace("–†–µ–º–æ–Ω—Ç –ù–æ–º.", "–†–µ–º–æ–Ω—Ç ‚Ññ")
    out = out.replace("–†–µ–º–æ–Ω—Ç –ù–µ—Ç.", "–†–µ–º–æ–Ω—Ç ‚Ññ")
    out = out.replace("–ù–µ—Ç.", "‚Ññ")
    out = out.replace("–®—Ç–∏—Ñ—Ç –®—Ç–∏—Ñ—Ç", "–®—Ç–∏—Ñ—Ç")
    return out


@dataclass(frozen=True)
class MockLLMClient:
    """Deterministic mock for tests and offline runs."""

    supports_repair: bool = True

    def translate(self, text: str, context: dict[str, Any]) -> str:
        task = str(context.get("task", "translate")).lower()
        if task == "repair":
            # Best-effort: return the provided OUTPUT block unchanged.
            return _extract_repair_output(text)
        return text


@dataclass(frozen=True)
class OpenAIChatCompletionsClient:
    """Minimal OpenAI Chat Completions client (template).

    Requires env:
      - OPENAI_API_KEY
    Optional:
      - OPENAI_BASE_URL (default https://api.openai.com)
    """

    model: str
    temperature: float = 0.1
    timeout_s: float = 60.0
    max_output_tokens: int = 2000
    base_url: str | None = None
    translation_system_prompt: str = SYSTEM_PROMPT_TEMPLATE
    glossary_replacements: tuple[GlossaryReplacement, ...] = ()
    reasoning_effort: str | None = None
    prompt_cache_key: str | None = None
    prompt_cache_retention: str | None = None
    structured_output_mode: str = "auto"
    supports_repair: bool = True

    def translate(self, text: str, context: dict[str, Any]) -> str:
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY is not set")

        task = str(context.get("task", "translate")).lower()
        structured_mode = _normalize_structured_output_mode(self.structured_output_mode)
        structured_for_text = task in {"translate", "repair"} and structured_mode != "off"
        if task == "repair":
            system_prompt = REPAIR_SYSTEM_PROMPT_TEMPLATE
            if structured_for_text:
                system_prompt += '\n\nReturn ONLY JSON object: {"repaired_text":"..."}'
        elif task == "batch_translate":
            system_prompt = BATCH_SYSTEM_PROMPT_TEMPLATE
        else:
            system_prompt = self.translation_system_prompt
            if structured_for_text:
                system_prompt += '\n\nReturn ONLY JSON object: {"translated_text":"..."}'

        base = (self.base_url or os.environ.get("OPENAI_BASE_URL", "https://api.openai.com")).rstrip("/")
        url = f"{base}/v1/chat/completions"

        model_reasoning_effort = self.reasoning_effort
        temperature: float | None = None
        if task == "repair":
            temperature = 0.0
        elif task == "batch_translate":
            temperature = 0.0 if _supports_temperature(self.model, model_reasoning_effort) else None
        elif _supports_temperature(self.model, model_reasoning_effort):
            temperature = self.temperature

        include_cache_key = bool(self.prompt_cache_key)
        include_cache_retention = bool(self.prompt_cache_retention)
        include_response_format = task == "batch_translate" or structured_for_text
        data: dict[str, Any] | None = None

        for _ in range(3):
            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": build_user_prompt(text, context)},
                ],
            }
            if _is_gpt5_family(self.model):
                payload["max_completion_tokens"] = self.max_output_tokens
            else:
                payload["max_tokens"] = self.max_output_tokens
            if temperature is not None:
                payload["temperature"] = temperature
            if model_reasoning_effort:
                payload["reasoning_effort"] = model_reasoning_effort
            if include_response_format:
                payload["response_format"] = {"type": "json_object"}
            if include_cache_key and self.prompt_cache_key:
                payload["prompt_cache_key"] = self.prompt_cache_key
            if include_cache_retention and self.prompt_cache_retention:
                payload["prompt_cache_retention"] = self.prompt_cache_retention

            req = urllib.request.Request(
                url=url,
                data=json.dumps(payload).encode("utf-8"),
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {api_key}",
                },
                method="POST",
            )

            try:
                with urllib.request.urlopen(req, timeout=self.timeout_s) as resp:
                    data = json.loads(resp.read().decode("utf-8"))
                break
            except urllib.error.HTTPError as e:
                body = e.read().decode("utf-8", errors="replace") if hasattr(e, "read") else ""
                body_l = body.lower()
                param: str | None = None
                try:
                    err_data = json.loads(body) if body else {}
                    param_raw = ((err_data.get("error", {}) or {}).get("param"))
                    param = str(param_raw) if param_raw is not None else None
                except Exception:
                    param = None

                if include_cache_retention and (
                    param == "prompt_cache_retention" or "prompt_cache_retention" in body_l
                ):
                    include_cache_retention = False
                    continue
                if include_cache_key and (param == "prompt_cache_key" or "prompt_cache_key" in body_l):
                    include_cache_key = False
                    continue
                if (
                    include_response_format
                    and structured_mode == "auto"
                    and (param == "response_format" or "response_format" in body_l)
                ):
                    include_response_format = False
                    continue
                raise RuntimeError(f"OpenAI HTTPError {e.code}: {body}") from e
            except Exception as e:
                raise RuntimeError(f"OpenAI request failed: {e}") from e

        if data is None:
            raise RuntimeError("OpenAI request failed after retries")

        try:
            content = data["choices"][0]["message"]["content"]
            if task == "batch_translate":
                return content
            if task == "repair":
                if structured_for_text or include_response_format:
                    try:
                        return _extract_structured_text(content, field_name="repaired_text")
                    except Exception as e:
                        if structured_mode == "strict":
                            raise RuntimeError(f"Strict structured repair parse failed: {e}") from e
                return _extract_repair_output(content)
            if structured_for_text or include_response_format:
                try:
                    content = _extract_structured_text(content, field_name="translated_text")
                except Exception as e:
                    if structured_mode == "strict":
                        raise RuntimeError(f"Strict structured translate parse failed: {e}") from e
            content = apply_glossary_replacements(content, self.glossary_replacements)
            return content
        except (KeyError, IndexError, TypeError) as e:
            raise RuntimeError(f"Unexpected OpenAI response schema: {data}") from e


@dataclass(frozen=True)
class GoogleFreeTranslateClient:
    """Google Translate free web endpoint client (no API key).

    This endpoint is unofficial and may change/rate-limit.
    """

    source_lang: str = "en"
    target_lang: str = "ru"
    timeout_s: float = 30.0
    base_url: str = "https://translate.googleapis.com"
    max_chunk_chars: int = 3800
    glossary_replacements: tuple[GlossaryReplacement, ...] = ()
    supports_repair: bool = False

    def _split_chunks(self, text: str) -> list[str]:
        if len(text) <= self.max_chunk_chars:
            return [text]

        chunks: list[str] = []
        cur = ""
        for part in text.splitlines(keepends=True):
            if len(part) > self.max_chunk_chars:
                if cur:
                    chunks.append(cur)
                    cur = ""
                for i in range(0, len(part), self.max_chunk_chars):
                    chunks.append(part[i : i + self.max_chunk_chars])
                continue

            if len(cur) + len(part) > self.max_chunk_chars:
                chunks.append(cur)
                cur = part
            else:
                cur += part

        if cur:
            chunks.append(cur)
        return chunks

    def _translate_chunk(self, text: str) -> str:
        query = urllib.parse.urlencode(
            {
                "client": "gtx",
                "sl": self.source_lang,
                "tl": self.target_lang,
                "dt": "t",
                "q": text,
            }
        )
        url = f"{self.base_url.rstrip('/')}/translate_a/single?{query}"
        req = urllib.request.Request(
            url=url,
            headers={"User-Agent": "docxru/0.1 (+free-google-endpoint)"},
            method="GET",
        )
        try:
            with urllib.request.urlopen(req, timeout=self.timeout_s) as resp:
                data = json.loads(resp.read().decode("utf-8"))
        except urllib.error.HTTPError as e:
            body = e.read().decode("utf-8", errors="replace") if hasattr(e, "read") else ""
            raise RuntimeError(f"Google free translate HTTPError {e.code}: {body}") from e
        except Exception as e:
            raise RuntimeError(f"Google free translate request failed: {e}") from e

        try:
            parts = data[0]
            return "".join(p[0] for p in parts if isinstance(p, list) and p and isinstance(p[0], str))
        except Exception as e:
            raise RuntimeError(f"Unexpected Google free translate response schema: {data}") from e

    def translate(self, text: str, context: dict[str, Any]) -> str:
        task = str(context.get("task", "translate")).lower()
        if task == "repair":
            # This provider cannot perform structural marker repair.
            return _extract_repair_output(text)
        translated = "".join(self._translate_chunk(chunk) for chunk in self._split_chunks(text))
        return apply_glossary_replacements(translated, self.glossary_replacements)


@dataclass(frozen=True)
class OllamaChatClient:
    """Local Ollama chat client for on-device translation."""

    model: str
    temperature: float = 0.1
    timeout_s: float = 60.0
    max_output_tokens: int = 2000
    base_url: str = "http://localhost:11434"
    translation_system_prompt: str = SYSTEM_PROMPT_TEMPLATE
    glossary_replacements: tuple[GlossaryReplacement, ...] = ()
    structured_output_mode: str = "auto"
    supports_repair: bool = True

    def translate(self, text: str, context: dict[str, Any]) -> str:
        task = str(context.get("task", "translate")).lower()
        structured_mode = _normalize_structured_output_mode(self.structured_output_mode)
        structured_for_text = task in {"translate", "repair"} and structured_mode != "off"
        if task == "repair":
            system_prompt = REPAIR_SYSTEM_PROMPT_TEMPLATE
            if structured_for_text:
                system_prompt += '\n\nReturn ONLY JSON object: {"repaired_text":"..."}'
        elif task == "batch_translate":
            system_prompt = BATCH_SYSTEM_PROMPT_TEMPLATE
        else:
            system_prompt = self.translation_system_prompt
            if structured_for_text:
                system_prompt += '\n\nReturn ONLY JSON object: {"translated_text":"..."}'
        url = f"{self.base_url.rstrip('/')}/api/chat"

        options: dict[str, Any] = {"num_predict": self.max_output_tokens}
        options["temperature"] = 0.0 if task in {"repair", "batch_translate"} else self.temperature

        include_json_format = task == "batch_translate" or structured_for_text
        data: dict[str, Any] | None = None
        for _ in range(2):
            payload = {
                "model": self.model,
                "stream": False,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": build_user_prompt(text, context)},
                ],
                "options": options,
            }
            if include_json_format:
                payload["format"] = "json"
            req = urllib.request.Request(
                url=url,
                data=json.dumps(payload).encode("utf-8"),
                headers={"Content-Type": "application/json"},
                method="POST",
            )

            try:
                with urllib.request.urlopen(req, timeout=self.timeout_s) as resp:
                    data = json.loads(resp.read().decode("utf-8"))
                break
            except urllib.error.HTTPError as e:
                body = e.read().decode("utf-8", errors="replace") if hasattr(e, "read") else ""
                body_l = body.lower()
                if include_json_format and structured_mode == "auto" and "format" in body_l:
                    include_json_format = False
                    continue
                raise RuntimeError(f"Ollama HTTPError {e.code}: {body}") from e
            except Exception as e:
                raise RuntimeError(f"Ollama request failed: {e}") from e

        if data is None:
            raise RuntimeError("Ollama request failed after retries")

        try:
            content = data["message"]["content"]
            if task == "batch_translate":
                return content
            if task == "repair":
                if structured_for_text or include_json_format:
                    try:
                        return _extract_structured_text(content, field_name="repaired_text")
                    except Exception as e:
                        if structured_mode == "strict":
                            raise RuntimeError(f"Strict structured repair parse failed: {e}") from e
                return _extract_repair_output(content)
            if structured_for_text or include_json_format:
                try:
                    content = _extract_structured_text(content, field_name="translated_text")
                except Exception as e:
                    if structured_mode == "strict":
                        raise RuntimeError(f"Strict structured translate parse failed: {e}") from e
            content = apply_glossary_replacements(content, self.glossary_replacements)
            return content
        except (KeyError, TypeError) as e:
            raise RuntimeError(f"Unexpected Ollama response schema: {data}") from e


def build_llm_client(
    provider: str,
    model: str,
    temperature: float,
    timeout_s: float,
    max_output_tokens: int,
    *,
    source_lang: str = "en",
    target_lang: str = "ru",
    base_url: str | None = None,
    custom_system_prompt: str | None = None,
    glossary_text: str | None = None,
    glossary_prompt_text: str | None = None,
    reasoning_effort: str | None = None,
    prompt_cache_key: str | None = None,
    prompt_cache_retention: str | None = None,
    structured_output_mode: str = "auto",
) -> LLMClient:
    provider_norm = provider.strip().lower()
    prompt_glossary_text = glossary_text if glossary_prompt_text is None else glossary_prompt_text
    translation_prompt = build_translation_system_prompt(
        SYSTEM_PROMPT_TEMPLATE,
        custom_system_prompt=custom_system_prompt,
        glossary_text=prompt_glossary_text,
    )
    glossary_replacements = build_domain_replacements() + build_glossary_replacements(glossary_text)
    if provider_norm == "mock":
        return MockLLMClient()
    if provider_norm == "openai":
        return OpenAIChatCompletionsClient(
            model=model,
            temperature=temperature,
            timeout_s=timeout_s,
            max_output_tokens=max_output_tokens,
            base_url=base_url,
            translation_system_prompt=translation_prompt,
            glossary_replacements=glossary_replacements,
            reasoning_effort=reasoning_effort,
            prompt_cache_key=prompt_cache_key,
            prompt_cache_retention=prompt_cache_retention,
            structured_output_mode=structured_output_mode,
        )
    if provider_norm == "google":
        return GoogleFreeTranslateClient(
            source_lang=source_lang,
            target_lang=target_lang,
            timeout_s=timeout_s,
            base_url=base_url or "https://translate.googleapis.com",
            glossary_replacements=glossary_replacements,
        )
    if provider_norm == "ollama":
        return OllamaChatClient(
            model=model,
            temperature=temperature,
            timeout_s=timeout_s,
            max_output_tokens=max_output_tokens,
            base_url=base_url or os.environ.get("OLLAMA_BASE_URL", "http://localhost:11434"),
            translation_system_prompt=translation_prompt,
            glossary_replacements=glossary_replacements,
            structured_output_mode=structured_output_mode,
        )
    raise ValueError(f"Unknown LLM provider: {provider}")
